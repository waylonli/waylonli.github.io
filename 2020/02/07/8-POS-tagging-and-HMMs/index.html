<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Waylon Li">





<title>8-POS tagging and HMMs | Waylon &amp; Ranee</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 4.2.0"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Waylon &amp; Ranee</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Waylon &amp; Ranee</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">8-POS tagging and HMMs</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Waylon Li</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">February 7, 2020&nbsp;&nbsp;22:39:42</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/Natural-Language-Processing/">Natural Language Processing</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="Pos-tagging"><a href="#Pos-tagging" class="headerlink" title="Pos tagging"></a>Pos tagging</h1><p>##Introduction</p>
<p><strong>Uses:</strong></p>
<ul>
<li>First step towards syntactic analysis</li>
<li>Often useful for semantic analysis</li>
<li>Illustrate the use of HMMs</li>
</ul>
<p><strong>Depends on:</strong></p>
<ul>
<li>The word to be labeled</li>
<li>The labels of surrounding words</li>
</ul>
<p><strong>Tags:</strong> Penn Treebank POS tags</p>
<img src="https://waylonranee.com/image/mdimg/image-20200205210126948.png" alt="image-20200205210126948" style="zoom:43%;" />

<p><strong>Difficulties:</strong></p>
<ul>
<li>Ambiguity</li>
<li>Sparse data</li>
</ul>
<h2 id="Probabilistic-model-for-tagging-forward-algorithm"><a href="#Probabilistic-model-for-tagging-forward-algorithm" class="headerlink" title="Probabilistic model for tagging (forward algorithm?)"></a>Probabilistic model for tagging (forward algorithm?)</h2><p><strong>Assumption:</strong></p>
<ul>
<li>Each tag depends only on previous tag (bigram tag model)</li>
<li>Words are independent given tags</li>
</ul>
<p><strong>Finite-state machine:</strong> sentences are generated by walking through states in a graph, each state represents a tag</p>
<p><strong>Given:</strong></p>
<ul>
<li>The transition and output proabilities</li>
<li>Sentence: $S=w_1\dots w_n$ </li>
<li>Tags of the sentence: $T=t_1 \dots t_n$ </li>
</ul>
<p>$$<br>P(S,T) = \prod_{i=1}^n P(t_i \mid t_{i-1}) P(w_i \mid t_i)<br>$$</p>
<h1 id="HMM"><a href="#HMM" class="headerlink" title="HMM"></a>HMM</h1><p>##Introduction</p>
<p><strong>Purpose:</strong> find the best tag sequence for an untagged sentence</p>
<ul>
<li>Markov: Markov independence assumption (each tag / state only depends on fixed number of previous tags / states)</li>
<li>Hidden: at test time we only see the words / emissions, the tags / states are hidden variables</li>
</ul>
<p><strong>Elements:</strong></p>
<ul>
<li>a set of states (e.g. tags)</li>
<li>a set of output symbol (e.g. words)</li>
<li>initial state (e.g. beginning of the sentence</li>
<li>state transition probabilities (e.g. $P(t_i \mid t_{i-1})$)</li>
<li>symbol emission probabilities (e.g. $P(w_i \mid t_i)$)</li>
</ul>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>$$<br>\underset{T}{\operatorname{argmax}} P(T \mid S) = \underset{T}{\operatorname{argmax}} P(S \mid T) P(T)<br>$$</p>
<ul>
<li>$T$: best tag sequence</li>
<li>$S$: untagged sentence</li>
<li>Using Bayes’ rule</li>
<li>P(T) = \prod_i P(t_i \mid t_{i-1})</li>
<li>$P(S \mid T) = \prod_i P(w_i \mid t_i)$</li>
</ul>
<h2 id="Searching-Viterbi-algorithm"><a href="#Searching-Viterbi-algorithm" class="headerlink" title="Searching: Viterbi algorithm"></a>Searching: Viterbi algorithm</h2><p><strong>Decoding</strong>: finding the best tag sequence for a sentence is called decoding</p>
<h2 id="Three-main-problems"><a href="#Three-main-problems" class="headerlink" title="Three main problems"></a>Three main problems</h2><ol>
<li><strong>Evaluation problem</strong><ul>
<li>Evaluation problem answers the question: what is the probability that a particular sequence of symbols is produced by a particular model?</li>
<li>For evaluation we use two algorithms: the <em>forward algorithm</em> or the <em>backwards algorithm</em> (DO NOT confuse them with the forward-backward algorithm).</li>
</ul>
</li>
<li><strong>Decoding problem</strong><ul>
<li>Decoding problem answers the question: Given a sequence of symbols (your observations) and a model, what is the most likely sequence of states that produced the sequence.</li>
<li>For decoding we use the <em>Viterbi algorithm</em>.</li>
</ul>
</li>
<li><strong>Training problem</strong><ul>
<li>Training problem answers the question: Given a model structure and a set of sequences, find the model that best fits the data.</li>
<li>For this problem we can use the following 3 algorithms:<ol>
<li>MLE (maximum likelihood estimation)</li>
<li>Viterbi training(DO NOT confuse with Viterbi decoding)</li>
<li>Baum Welch = forward-backward algorithm</li>
</ol>
</li>
</ul>
</li>
</ol>

        </div>

        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/Notes/"># Notes</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
            
            <a class="next" rel="next" href="/2020/02/07/7-Text-Classification/">7-Text Classification</a>
            
        </section>


    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        Think in the morning. Act in the noon. Eat in the evening. Sleep in the night.
    </div>
</footer>

    </div>
</body>
</html>
